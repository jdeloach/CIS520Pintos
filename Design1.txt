
CIS 520 - Programming Project #1

                   
---- GROUP ----

>> Fill in the names and email addresses of your group members.

Jordan DeLoach		jdeloach@ksu.edu 
Simon Novelly		trentn@ksu.edu
Micheal Whitehead	mwhite14@ksu.edu
...

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for
>> the TA, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation,
>> course text, lecture notes, and course staff.


                 ALARM CLOCK
                 ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

src/devices/timer.c
static struct list wait_list;
	Holds the list of waiting threads to be woken up.

src/threads/thread.h
struct thread
	defines a thread and all its properties
	changed - added
		struct semaphore wait_sem;
			keeps track of if the thread has been blocked or not
		struct list_elem wait_elem;



---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to your timer_sleep(),
>> including the effects of the timer interrupt handler.

	We add the thread to the waiting list, then set the wait_time for the thread.
	We use a semaphore to block thread, so once the wait time has been set, we initialize the wait_sem to 0, and call sema_down effectively blocking the thread.
	Each time the timer interrupt is called, it searches the the wait_list for any threads that have a expired wait time and call sema_up on their wait_sems waking them back up.


>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?
	
	The threads have been given a wake time, and the timer interrupt simply compares that wake time to the current time, and it the wakes the thread if the wake time has expired, as opposed to setting a number of ticks to decrement in the thread and decrementing the ticks for each thread that has been sleeping.

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

	We disable interrupts when updating the wait_list, so that we are sure that the wait_list is updated properly.

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?
	
	As mentioned interrupts are disabled whe updating wait_list, so if it is called during that time nothing happens.

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> other designs that you considered?

	We chose this design because semaphores are a fast way of handling thread_sleeping. It saves time in the timer interrupt because now the interrupt just keeps track of who needs to be woken and does not calculate anything in the threads.

	Other designs involved setting a ticks value which the timer interrupt decremented for each thread and then checked which threads were at 0. We thought this would have too much over head.


             PRIORITY SCHEDULING
             ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

thread.h
    struct lock *lock_wanted;
    	Lock that this thread is attempting to acquire.
    
    struct thread *lock_holder;
    	The thread who you donate your priority to.
	
    int original_priority;
    	Your "true" priority, before receiving any donations. Will return to this value when no longer 
    	holding any important locks.
    	
    struct list priority_recieving;
    	The list of threads donating to this thread.
    
    struct list_elem recieving_elem;
    	Element for the list where this thread is donating to another thread.

>> B2: Explain the data structure used to track priority donation.

	The most significant data structure used to track priority donation is each threads list from 
	whom it receives donations. The two primary interactions with this structure is when a lock is 
	trying to be acquired, and released. When a lock is attempting to be acquired, the current thread 
	gets added to the list and becomes a "donor" to the thread owning the lock. Eventually, once the 
	lock owner, and any higher-priority-waiters get the lock, and the thread gets the lock, it will 
	use the resource and then release. In release, the lock is released, priorities are returned to 
	their thread owners, and the lock is then given on to the next highest priority, as determined 
	through the receiving list.

---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?

	We maintain a sorted lists of threads waiting to be woken up.
	These lists are sorted according to priority so that the highest priority are always at the front.

	For a semaphore, when sema_up is called, the list of waiters is sorted and the first thread woken up.
	Locks depend on semaphores, so because the waiters for a semaphore are sorted, the lock functions in the same way.
	Thus for both semaphores and locks, we maintain a list of threads, sorted using a sorting function which sorts from greatest to least.

	The condition variable works a little different, because it maintains a list of semaphores, each having one thread waiting on it. 
	We have to sort this list of semaphores according to the threads waiting on them.
	We have a separate sorting function which sorts semaphores based on the priority of the threads waiting on them.

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?

	When a thread makes a call to lock_acquire() the following occurs:
		
		1. Assert that the lock exists, it is not in an interrupt context, and it is not already held by itself.
		2. Disable interrupts
		3. Check that the lock is currently available
		4. If the lock is currently held (not available):
			a. The current thread (thread trying to acquire the lock) saves who has the lock and which lock it wants.
			b. The current thread then adds itself to the lock holder's donor list (priority_recieving)
			c. The lock holder's priority then gets recomputed as needed (i.e. if the donor has a greater priority, the lock holder gets set to that priority)
		5. The current thread then sema_downs on the e lock's semaphore, and either gets blocked or acquires the lock.
		6. Once the thread acquires the lock it sets itself as the lock holder and clears what lock it wants.
		7. Enable interrupts

>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

	When a thread makes a call to lock_release() the following occurs:

 		1. Assert that the lock exists and that itself is the current lock holder.
		2. Disable interrupts
		3. If the lock's semaphore waiting list is not empty:
			a. Remove the threads waiting on the lock from the current thread's (thread releasing the lock) donor list.
			b. Recompute the current thread's priority:
				 i. Set to either the next highest priority in the donor list
				ii. Or if there is no one in the donor list -> set back to base priority
		4. The current thread then releases the lock by clearing the lock holder, signaling the lock's semaphore. When the semaphore is signaled, the thread yields if there is a higher priority thread ready to run.
		5. Enable interrupts
		

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

	There is a potential race condition when calling thread_set_priority when updating the thread's priority, and original priority.	
	We disable interrupts inside this function when the priority information is being updated to prevent this from happening.

	It would depend on how the lock is implemented. Using a lock in this case would added extra overhead, which is eliminated by simply disabling interrupts.

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

	Our design allows us to leverage much of the functionality which is already a part of the Pintos system.
	We are mainly adding sorting to many of the lists which are already maintained to keep track of priority.
	Priority donation posed a bit more of a challenge however. The design we chose has the thread keep track of who it is recieving priority from, who it needs a lock from, and which lock it wants.
	The lock just keeps track of who has it. This allows for the least amount of overhead, as we can map out dependencies based on this information, and really only have one list to keep track of per thread.

	This was the most natural development, and we did not consider very many other designs in regards to keeping track of the highest priority.
	We could have simply selected the max element from the list, but that also involves sorting, so this design is simpler to keep track of.
	We also considered having the thread track who it had donated priority to, but that was not necessary

              ADVANCED SCHEDULER [EXTRA CREDIT]
              =================================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0
 4
 8
12
16
20
24
28
32
36

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

